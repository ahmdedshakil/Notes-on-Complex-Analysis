\documentclass{article}
\usepackage[homework]{ahmeds}

\initialize{}

\begin{document}

\start{Ahmed Shakil}{Math H185}{Midterm 1 Review}

\tableofcontents

\newpage

\section{Tools and Tricks}

\begin{misc}{Properties of the modulus}{}
\begin{align*}
    z\overline{z} &= \left\lvert z \right\rvert ^{2} \\
    \overline{z\cdot w}&= \overline{z} \cdot \overline{w}  \\
    \left\lvert z\cdot w \right\rvert &= \left\lvert z \right\rvert \cdot \left\lvert w \right\rvert 
\end{align*}

\end{misc}

\begin{misc}{\( z^n = \omega  \) }{}
Let \( \omega = re^{i \theta } \), with \( r>0 \), and \( n>0 \).
\begin{align*}
    z^n &= \omega \\
    z &= \sqrt[n]{r} e^{i (\frac{\theta + 2\pi k}{n}) }, k \in \left\{ 0,1, \dots , n - 1 \right\} 
\end{align*}

\end{misc}

\begin{misc}{Standard nonholomorphic functions}{}
The following functions are \( \mathbb{C} \to \mathbb{C}  \) and are not holomorphic at any point in the complex plane. 

\begin{align*}
    f_1(z) &= |z|\\
    f_2(z) &= \overline{z} 
\end{align*}

\end{misc}

\begin{misc}{Expansion of \( e^x \) }{}
\begin{align*}
    e^z = \sum_{n \geq 0} \frac{z^n}{n!}
\end{align*}

\end{misc}

\begin{misc}{Some useful limits}{}
\begin{align*}
    \lim_{n \to \infty} \sqrt[n]{n} = 1
\end{align*}

\end{misc}

\begin{misc}{Bounding the \( \sin \) function}{}
\begin{align*}
    \sin \theta \geq \frac{2\theta }{\pi }, \ \ \theta \in \left[ 0, \frac{\pi}{2} \right]  
\end{align*}
Note to self: Look for a tighter bound. (Check my hw)
\end{misc}


\newpage 

\section{Imaginary Numbers and Complex Variables}

We start with the concept of an imaginary number, we define \( i \coloneqq \sqrt{- 1}  \). A complex number is \( z \coloneqq a + bi \) where \( a, b \in \mathbb{R} \). We regard \( \mathbb{C}  \) as the algebraic closure of \( \mathbb{R}  \). We denote the "real part" of \( z \) as \( \Re (z) \), similarly we denote the "imaginary part" of \( z \) as \( \Im (z) \). We denote the complex conjugate as \( \overline{z} \coloneqq a - bi \), and the set of complex numbers as \( \mathbb{C} \). 

Operations on complex numbers are similar to operations on the real numbers. Addition is component wise, and multiplication distributes. Addition and multiplication satisfy the usual commutativity, associativity, and distributivity rules. Division is a bit nuanced:
\begin{misc}{Division in \( \mathbb{C} \) }{}
If \( z,w \in \mathbb{C}  \), and \( w \neq 0 \), then \( \frac{z}{w} \in \mathbb{C}  \) is the unique complex number such that \( (\frac{z}{w})\cdot w = z. \) 
\end{misc}

Geometrically we view \( \mathbb{C} \) as a two-dimensional plane where the \( y \) axis is the imaginary axis and the \( x \) axis is the real axis. We denote the absolute value (modulus) of \( z = a + bi\in \mathbb{C} \) as \( \left\lvert z \right\rvert \coloneqq \sqrt{a^{2} + b^{2} }  \). Addition of complex numbers can be seen as addition of vectors in two dimensions. 

We can translate \(  z \in \mathbb{C}  \) by describing them in polar form instead. 
\begin{misc}{Polar form of complex numbers}{}
\begin{align*}
    \text{Polar }&  \quad \text{ Cartesian} \\
    (r, \theta )& \to (x,y) \\
    (\sqrt{x^{2} + y^{2}}, \arctan (\frac{y}{x}))& \leftarrow (x,y)\\
    \\
    re^{i \theta }& \to r\cos \theta + ir\sin \theta \\
    |z|e^{i\arctan (\frac{y}{x})}& \leftarrow z = x + iy  
\end{align*}
We view \( \theta  \) as the angle from the \( x \) axis in the counter-clockwise direction, and \( r \) as the straight line distance from the point in the complex plane to the origin. 
\end{misc}

\begin{thrm}{Euler's Theorem}{}
\begin{align*}
    e^{iz} = \cos (z) + i\sin (z)  
\end{align*}

\begin{proof}
Follows from Taylor series expansion formulas.
\end{proof}

\end{thrm}

\subsection{Topology of \(\mathbb{C}\)}

As a metric space we make a sort of equivalence between \( \mathbb{C}  \) and \( \mathbb{R}^2  \). In a sense, 
\begin{align*}
    \mathbb{C}& \simeq \mathbb{R} ^2\\
    z = x + iy& \leftrightarrow (x,y)\\
    |z| = \sqrt{x^{2} + y^{2} }& \quad \ |(x, y)| = \sqrt{x^{2} + y^{2} }  
\end{align*}

\begin{exmp}{Neighborhoods in \( \mathbb{C}  \) }{}
Let \( z_0 \in \mathbb{C}  \) and \( 0<r\in \mathbb{R}  \).
\[
    \overline{B_{r} (z_0) }\coloneqq \left\{ z \in \mathbb{C} : |z - z_0| \leq  r \right\}  
\]
is the closed ball of radius \( r \) around \( z_0. \) 

Similarly, 
\[
    B_{r} (z_0) \coloneqq \left\{ z\in \mathbb{C} : |z - z_0| <r \right\} 
\]
is the open ball.

A subset \( U \subset \mathbb{C}  \) is open if \( \forall z \in U \), \( \exists 0<r\in \mathbb{R}  \)  such that \( B_{r} (z) \subset U  \). 
\end{exmp}

It is important to note that a sequence \( \left\{ z_n = x_{n} + iy_{n}  \right\} \subset \mathbb{C}   \)  converges to \( z \in \mathbb{C} \) if and only if 
\[
    \lim_{n \to \infty} x_{n} = x \text{  and  } \lim_{n \to \infty} y_{n} = y.
\]

\section{Complex Derivatives}

Let \( U \) be an open subset of \( \mathbb{C} \) and \( f: U \to \mathbb{C}  \) be a function. 

\begin{defn}{Holomorphic at a point}{}
We say \( f \) is holomorphic at some point \( z_0 \) if \( \lim_{h \to 0} \frac{f(z_{0} + h )- f(z)}{h}  \) exists in \( \mathbb{C} \). Equivalently it is holomorphic at \( z_0 \) if the following limit exists
\[
    \lim_{z_0 \to z} \frac{f(z)- f(z_0)}{z - z_{0}} .
\]
If these limits exists, then we denote the value as \( f^\prime (z_0) \).
\end{defn}

\begin{rmk}{About holomorphic functions}{}
Holomorphicity is a property which is quite a lot stronger than typically differentiability in the real number world. Holomorphicity means we demand the limit to be the same along any path of approach to a particular point. A common example of a function which is not holomorphic due to limits not being consistent along different paths of approach is the conjugation function: \( f(z) = \overline{z} . \) This function is not holomorphic at any point in the complex plane. 

\hfill

Some cool properties of holomorphic functions
\begin{itemize}
    \item If a function is holomorphic at a point, then it is automatically infinitely complex differentiable at this particular point
    \item If \( f,g \) are holomorphic on a connected \( U \subset \mathbb{C}  \) and \( f = g \) on a line segment, then \( f = g  \) on all of \( U \) 
\end{itemize}
\end{rmk}

Something important to note about complex differentiation is that the typical differentiation rules from the real numbers hold. So things like the product, quotient, chain, and addition rules hold. Also, the rules for differentiating polynomials are the same as well. Ratio of polynomials are holomorphic at all points in the complex plan other than the points at which the denominator is equal to \( 0 \).

\section{Power Series}

A power series is an expression of the following form:
\[
    \sum_{n\geq 0} a_{n} z^n = a_{0} + a_{1}z + a_2 z^{2} + \dots   
\]

\begin{rmk}{Manipulating power series}{}
Addition:
\[
    (\sum_{n\geq 0} a_{n} z^n )+(\sum_{n \geq 0} b_{n} z^n) = \sum_{n\geq 0} (a_{n} + b_{n} )z^n 
\]

Multiplication:
\[
    (\sum_{n\geq 0}a_{n} z^n )(\sum_{n\geq 0} b_{n} z^n ) = \sum_{n\geq 0}(\sum_{j + k = n}a_{j} b_{k}  )z^n 
\]
\end{rmk}

A power series defines a function when it converges. 

\begin{exmp}{Geometric Series}{}
Let \( a \in \mathbb{C}  \) 
\[
    \sum_{n\geq 0} a^n z^n
\]
is called the geometric series. 

The convergence of this power series can be contemplated by taking a look at the partial sums. For example,
\[
    \sum_{n\geq 0}^{N - 1} a^n z^n = \frac{1 -(az)^N}{1 - az} .
\]

Now based on this we see that if \( |az| < 1 \) then the series converges, on the other hand if \(|az| > 1 \) then the series diverges. If we have that \( |az| = 1 \) then it is less clear as to if the series converges or diverges. If \( az = 1 \) then the series diverges and \( (az)^n \) amounts to moving around the unit circle without converging. Ultimately, the geometric series converges if and only if \( |z| < \frac{1}{a} \).
\end{exmp}

Recall that we say \( \sum z_{n}   \) converges absolutely if \( \sum |z_{n} | \) converges. Also recall that absolute convergence implies convergence. 

\begin{defn}{Radius of Convergence}{}
For a power series \( \sum_{n\geq 0}  a_{n} z^n\), we define the radius of convergence as 
\[
    r\coloneqq (\limsup_{n \to \infty} |a_{n} |^\frac{1}{n})^{-1} 
\]
\end{defn}

\begin{thrm}{Convergence of power series}{}
\begin{enumerate}[]
    \item If \( |z| < r \), then the power series converges absolutely.
    \item If \( |z| >r \), then the power series diverges. 
    \item If \( |z| = r \), then more examination is required, the series could converge or diverge. 
\end{enumerate}
\end{thrm}



\subsection{Differentiation of Power Series}

For \( z_0 \in \mathbb{C}  \), a power series centered at \( z_0 \) is an expression
\[
    f(z) \coloneqq \sum_{n\geq 0} a_{n}(z - z_0)^n 
\]

Once again, it's radius of convergence is given by \( r\coloneqq (\limsup_{n \to \infty} |a_{n} |^\frac{1}{n})^{-1} \), and it converges absolutely for \( |z - z_0| < r \) .

\begin{thrm}{}{}
\begin{enumerate}[]
    \item $f(z)$ is holomorphic at all \( z \in  B_{r} (z_0) \), and 
    \item \( f'(z) = \sum_{n\geq 0} na_{n} z^{n- 1}   \) is also holomorphic on \( B_{r} (z_0) \) with the same radius of convergence. 
\end{enumerate}
\end{thrm}

\begin{defn}{Analytic function}{}
A function \( f: U \to \mathbb{C}  \) on an open subset \( U \subset \mathbb{C}  \) is analytic if for every \( z_0 \in  U \), \( \exists \ r>0  \) such that \( f \) agrees with an absolutely convergent power series on \( B_{r} (z_0) \). 
\end{defn}

Examples of analytic functions are \( \sin (z) \) and \( \cos (z) \). 

\subsection{Cauchy-Riemann Equations}

As we mentioned before \C{} is basically isomorphic to \R{2} when viewed as metric spaces. However, in terms of differentiability they are not the same. Now say we have some open \( \Omega \subset \mathbb{C} \) and \( f: \Omega \to \mathbb{C}  \). We can write \( f \) as the following function:
\begin{align*}
    f &= u + iv, \text{\quad where } \\ 
    u &= \Re (f): \Omega \to \mathbb{C} \\
    v &= \Im (f): \Omega \to \mathbb{C} 
\end{align*}

Using this, given some \( z = x + iy \), we view \( u(z) = u(x,y) \) and the same goes for \( v \) as well. 

\begin{thrm}{Cauchy-Riemman Equations}{}
If \( f \) is holomorphic at \( z _0 \), then 
\begin{align*}
    \frac{\partial u}{\partial x}(z_0) &= \frac{\partial v}{\partial y}(z_0) \\
    \frac{\partial u}{\partial y}(z_0) &= - \frac{\partial v}{\partial x}(z_0) \\
\end{align*}
These are called the Cauchy-Riemann equations. 
    \tcbline

    \begin{proof}
    \begin{align*}
        \lim_{{\underset{\in \mathbb{R}}{x}  \to 0}} = \frac{f(z_0 + x)- f(z_0)}{x} = f& ^\prime(z_0) = \lim_{\underset{\in \mathbb{R} }{y}  \to 0} \frac{f(z_0+ iy) - f(z_0)}{iy} \\ 
        \frac{\partial f}{\partial x}(z_0) &= \frac{1}{i}\frac{\partial f }{\partial y}(z_0) \\
        \frac{\partial u}{\partial x} (z_0) + i \frac{\partial v}{\partial x} (z_0) &= \frac{1}{i}(\frac{\partial u}{\partial y} (z_0) + i\frac{\partial v}{\partial y} (z_0))  \\
        \implies  &\begin{cases}
        \frac{\partial u}{\partial x}(z_0) &= \frac{\partial v}{\partial y}(z_0) \\
        \frac{\partial u}{\partial y}(z_0) &= - \frac{\partial v}{\partial x}(z_0) \\
        \end{cases}
    \end{align*}
    
    \end{proof}
    \tcbline

    It is also important to note that there exists a converse result. If \( f \) is in \( C^1 \), meaning \( \frac{\partial u}{\partial x} , \frac{\partial u}{\partial y} , \frac{\partial v}{\partial x} , \frac{\partial v}{\partial y}  \) all exist and are continuous, and the Cauchy-Riemann equations hold, then \(  f \) is holomorphic. 
\end{thrm}

The partial derivative matrix of a holomorphic function has the following special form:
\begin{align*}
    \begin{bmatrix}
        \frac{\partial u}{\partial x}  & \frac{\partial u}{\partial y}   \\
         \frac{\partial v}{\partial x} &  \frac{\partial v}{\partial y}  \\
    \end{bmatrix} = \begin{bmatrix}
        a &   b \\
        -b &  a \\
    \end{bmatrix}
\end{align*}

It is important to note that holomorphic functions are conformal mappings, meaning they infinitesimally preserve angles or scale them to 0.

\section{Integrating Over Curves}

Integrating in complex analysis in the most basic sense amounts to the following.
\[
    \int f(z) dz = \int \Re (f(z))dz + \int \Im (f(z)) dz
\]

\subsection{Curves}

The idea is the connect \( \int _\gamma  \) to \( \int _a^b \) using substitution, where \( \gamma  \) is a curve.

\begin{defn}{Parametrized Curve}{}
A parametrized curve is a continuous function
\[
    \gamma (t): [a,b] \subset \mathbb{R} \to \mathbb{C} 
\]
\end{defn}

We say a curve \( \gamma  \) is piecewise smooth if we can divide the domain \( [a,b] \) into finitely many subintervals on which \( \gamma  \) is smooth (i.e. infinitely differentiable).

\subsubsection{Integration on Parametrized Curves}

\begin{thrm}{$U$-substitution}{}
If \( \gamma : [a,b] \to \mathbb{C}  \) is piecewise-smooth, and \( f \) is defined on the image of \( \gamma \), then 
\[
    \boxed{\int _\gamma  f(z) dz = \int ^b_a f(\gamma (t))\gamma ^\prime (t) dt.} 
\]
\end{thrm}

An important property to note is that reversing the orientation of the curve is equal to taking the negative of the original curve. The reverse of \( \gamma  \) is defined as follows.
\[
    \gamma ^-(t ) = \gamma (b + a - t)
\]
Then \(- \int _{\gamma ^-} f(z) dz = \int _\gamma f(z) dz \). As a matter of definitions it is important to note that we refer to an antiderivative as a primitive, these terms should be taken as one and the same. 

\begin{thrm}{Fundamental Theorem of Calculus}{}
\[
    \int_\gamma f(z) dz = F(\gamma (b)) - F(\gamma (a))
\]
\tcbline
\emph{Corollary:}

If \( \gamma : [a,b]\to \mathbb{C}  \) is a closed loop, i.e. \( \gamma (a) = \gamma (b) \), then 
\[
    \int _\gamma f(z) dz = F(\gamma (b)) - F(\gamma (a)) = 0
\]
\end{thrm}

\begin{exmp}{The most fundamental example}{}
Say \( f(z) = z^n \) and \( n \in \mathbb{Z}  \). Consider the curve \( \gamma (t)= re^{it}  \) where \( r \in \mathbb{R} _{>0} \) and \( t \in [0, 2\pi ] \).
Calculate \( \int _\gamma f(z) dz \) for all \( n \in \mathbb{Z}  \).
\tcbline

\begin{align*}
    \int _\gamma f(z) dz &= \int_{0}^{2\pi} r^n e^{nit} (rie^{it}) dt \\ 
    &= ir^{n+ 1} \int _0^{2\pi } e^{(n + 1)it} dt
\end{align*}

\underline{If \( n\neq 1 \):} A primitive for \( e^{(n + 1)it} \)  is \( \frac{1}{(n + 1)i} e^{(n + 1)it}\).

\begin{align*}
    \implies \boxed{\int_\gamma f(z) dz = 0 \tag{$n \neq - 1$}} 
\end{align*}

\underline{If \( n = -1 \):}
\begin{align*}
    ir^{0} \int _0^{2\pi } e^{(0)it} dt = 2\pi i\\
    \implies \boxed{\int_\gamma f(z) dz = 2\pi i \tag{$n = - 1$}}
\end{align*}

\underline{Conclusion:}

\begin{align*}
    \int _{\partial B_r(0)}z^n dz = \begin{cases}
        0 \ \ &n\neq - 1 \\
        2\pi i \ \ &n = - 1
    \end{cases}
\end{align*}


\end{exmp}

\subsubsection{Cauchy's Theorem}

A boundary of a subset \( \Omega \subset \mathbb{C}  \) is \( \overline{\Omega }\setminus  \Omega ^\circ  \). Basically the boundary is the points in the closure of a set which is not in the interior of the set. 

An important thing to note about substitutions:
If \( g(z) \) is holomorphic on an open neighborhood of \( \gamma  \) 
\begin{align*}
    \int _\gamma f(g(z)) dz = \int _{g \circ \gamma } f(z) g^\prime (z) dz.
\end{align*}

\begin{thrm}{Cauchy's Theorem}{}
If \( U \subset \mathbb{C}  \) is an open set and has a piecewise-smooth boundary, and \( f(z) \) is holomorphic on a domain containing \( \overline{U}  \), then
\[
    \int _{\partial U } f(z) dz = 0.
\]

This is the most fundamental and remarkable tool in complex analysis.

\end{thrm}


Contour manipulation is an important technique to note. This is because to calculate an integral on a curve, we can deform that curve through a domain where our function is holomorphic in order to calculate our desired result. 

\begin{thrm}{Cauchy's formula}{}   
Suppose we have \( f: \Omega \subset \mathbb{C}  \to \mathbb{C}  \) which is defined on an open set as the domain, and is holomorphic. Let \( z_0 \in \Omega  \) and \( r > 0 \) such that \( B_r(z_0) \subset \Omega  \). Then for all \( z \in B_ r(z_0), \) we have 
\[
    f(z) = \frac{1}{2\pi i}\int _{\partial B_r(z_0)}\frac{f(w)}{w - z}dw. 
\]

\tcbline
\begin{proof}
Take a delta ball around some hole \( f(z) \)  and use it to approximate \( f(w) \), then show the error goes to zero. \end{proof}

\end{thrm}

\begin{cor}{Infinite differentiability}{}
As a result of Cauchy's formula we have that wherever \( f \) is holomorphic it is infinitely differentiable. 

We can differentiate Cauchy's formula to derive the following more general formula for higher order derivatives:

\begin{align*}
    \boxed{f^{(n)}(z) = \frac{n!}{2\pi i}\int _{\partial B_r(z_0) } \frac{f(w)}{(w - z)^{n+ 1} } dw }
\end{align*}

\end{cor}

\begin{lem}{Jordan's Lemma}{}
Let \( f(z) = e^{iaz}g(z)  \)  where \( z \in \mathbb{C} \) and \( a > 0 \).

Then
\[
    \left\lvert \int _\gamma f(z) dz \right\rvert \leq \frac{\pi}{a}\sup _{\gamma }\left\lvert g(z) \right\rvert .
\]
Note that the curve is a semicircle with \( R \) as the radius.
\end{lem}

\begin{thrm}{Goursat's Theorem}{}
If \( f(z) \) is holomorphic on a neighborhood containing \( \Delta   \) then 
\[
    \int _\Delta f(z) dz = 0.
\]
\end{thrm}






\begin{thrm}{}{}
If \( f \) is holomorphic on a ball \( B_r(z_0) \) where \( z_0 \in \mathbb{C}  \) and \( r>0 \), then \( f \) has a primitive on \( B_r(z_0) \).
\end{thrm}

\begin{defn}{Homotopic Curves}{}
Say we are given two parametrized curves (where \( U \subset \mathbb{C}  \) is an open set)
\begin{align*}
    \gamma _0: \left[ a,b \right] \to U \\
    \gamma _1: \left[ a,b \right] \to U \\
\end{align*}
 where 
\begin{align*}
    \gamma _0(a) = \gamma_1(a) = z_a \\
    \gamma _0(b) = \gamma _1(b) = z_b.
\end{align*}
We say \( \gamma _0  \) and \( \gamma _1 \) are homotopic in \( U \) if there exists a jointly continuous \( \gamma _s (t) \) where \( s \in [0, 1] \) and \( t \in \left[ a,b \right]  \) such that \begin{align*}
    \gamma _s(a) = z_a \quad \forall s\\
    \gamma _s(b) = z_b \quad \forall s\\
    \gamma _s (t) \mid _{s = 0} = \gamma _0(t) \\
    \gamma _s (t) \mid _{s = 1} = \gamma _1(t) \\
\end{align*}

\end{defn}
\begin{defn}{Simply Connected}{}
We say \( U \) is simply connected if any two curves \( \gamma _0 \) and \( \gamma _1 \) in \( U \) with the same end points are homotopic in \( U \). 
\end{defn}

\begin{thrm}{Equivalence of Homotopic Curves}{}
If \( f \) is holomorphic on a open subset \( U \subset \mathbb{C}  \) where \( \gamma _0 \) and \( \gamma _1 \) are homotopic in \( U \), then 
\[
    \int _{\gamma _0}f(z) dz = \int _{\gamma _1}f(z) dz.
\]
\end{thrm}

\begin{thrm}{Existence of Primitives}{}
Any holomorphic function \( f \) on a simply connected domain \( U \subset \mathbb{C}  \) has a primitive \( F \) on \( U \). 
\end{thrm}


\end{document}